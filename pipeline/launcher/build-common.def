#------------------------------------------------------------------------------
# These sections are appended to all assembled pipeline-level singularity.def files,
# after replacing __VAR_NAME__ with ${VAR_NAME}.
#------------------------------------------------------------------------------
# https://sylabs.io/guides/latest/user-guide/definition_files.html
#------------------------------------------------------------------------------
# STATIC_MDI_DIR=/srv/static/mdi is an mdi-centric, read-only MDI installation that is 
# copied into the image and updated at build time, used by running pipelines.
# It is where the pipelines framework and environments are drawn from. 
#------------------------------------------------------------------------------
# TASK_DIR is a user-defined, active, read-write folder bind-mounted at run time. 
# In addition to being where pipelines deposit data files, TASK_DIR has a fixed, 
# static copy of the tool suite code required to execute a pipeline.
#------------------------------------------------------------------------------

# copy the pipelines-relevant mdi installation into the container and reset for use
%setup
    SRV_DIR=/srv
    STATIC_DIR=${SINGULARITY_ROOTFS}${SRV_DIR}/static
    STATIC_MDI_DIR=${STATIC_DIR}/mdi
    mkdir -p ${STATIC_MDI_DIR}/environments
    mkdir -p ${STATIC_MDI_DIR}/resources
    cp -r ./config      ${STATIC_MDI_DIR}/config
    cp -r ./frameworks  ${STATIC_MDI_DIR}/frameworks
    cp -r ./suites      ${STATIC_MDI_DIR}/suites
    cp    ./mdi         ${STATIC_MDI_DIR}/mdi
    rm -f ${STATIC_MDI_DIR}/suites/*.lock

# install the software required by pipeline actions as conda environments
%post

    # path variables set by us
    export SRV_DIR=/srv
    export MINICONDA_DIR=${SRV_DIR}/miniconda  
    export PATH=${MINICONDA_DIR}/bin:${PATH}  
    export STATIC_DIR=${SRV_DIR}/static 
    export STATIC_MDI_DIR=${STATIC_DIR}/mdi 

    # variables set by mdi build
    SUITE_VERSION=__SUITE_VERSION__
    PIPELINE_NAME=__PIPELINE_NAME__
    INSTALLER=__INSTALLER__

    # install git, conda and zip, as used by the MDI
    if [ "$INSTALLER" = "apt-get" ] || \
       [ "$INSTALLER" = "yum" ]; then
        $INSTALLER update && $INSTALLER install -y git wget zip
    else 
        echo "unknown installer: $INSTALLER"
        exit 1
    fi
    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ${SRV_DIR}/miniconda.sh
    bash ${SRV_DIR}/miniconda.sh -b -p ${MINICONDA_DIR} 

    # set conda channel_priority to strict
    # https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-channels.html#strict-channel-priority
    # https://github.com/conda/conda/issues/8197
    conda config --set channel_priority strict

    # creata conda environments of the software required by the pipeline
    export IS_CONTAINER_BUILD=TRUE
    ${STATIC_MDI_DIR}/mdi ${PIPELINE_NAME} conda --create --force --no-mamba --version ${SUITE_VERSION} 

    # clean up conda pkgs directory of cached tarballs (conda clean won't work here)
    rm -f ${MINICONDA_DIR}/pkgs/*.tar.bz2

# path overrides include all ways that running pipelines use files from mdi-pipelines-framework
# https://sylabs.io/guides/latest/user-guide/environment_and_metadata.html#environment-and-metadata
%environment 
    export LC_ALL=C

    # conda path specifications
    export SRV_DIR=/srv
    export MINICONDA_DIR=${SRV_DIR}/miniconda  
    export PATH=${MINICONDA_DIR}/bin:${PATH}     
    export CONDA_LOAD_COMMAND=""
    export CONDA_PROFILE_SCRIPT=${MINICONDA_DIR}/etc/profile.d/conda.sh

    # static, read only, code path specifications; environments, pipelines framework
    export STATIC_DIR=${SRV_DIR}/static 
    export STATIC_MDI_DIR=${STATIC_DIR}/mdi 
    export MDI_DIR=${STATIC_MDI_DIR}
    export ENVIRONMENTS_DIR=${STATIC_MDI_DIR}/environments
    # export RESOURCES_DIR=${STATIC_MDI_DIR}/resources    
    export FRAMEWORK_DIR=${STATIC_MDI_DIR}/frameworks/definitive/mdi-pipelines-framework
    export JOB_MANAGER_DIR=${FRAMEWORK_DIR}/job_manager
    export LAUNCHER_DIR=${FRAMEWORK_DIR}/pipeline/launcher
    export WORKFLOW_DIR=${FRAMEWORK_DIR}/pipeline/workflow
    export WORKFLOW_SH=${WORKFLOW_DIR}/workflow.sh
    export SLURP=${FRAMEWORK_DIR}/shell/slurp   

    # no read-write code folder needed
    # a static copy of versioned suite code is placed in bind-mounted TASK_DIR

# scriplet called by execute.pl to launch the pipeline; it takes no arguments
%runscript
    exec bash ${LAUNCHER_DIR}/execute.sh

# labels for the container image, displayed as 'singularity inspect __PIPELINE_NAME__-__PIPELINE_VERSION__.sif'
%labels
    Source Michigan Data Interface
    SuiteName __SUITE_NAME__
    SuiteVersion __SUITE_VERSION__
    PipelineName __PIPELINE_NAME__
    PipelineVersion __PIPELINE_VERSION__
    ContainerBase __CONTAINER_BASE__
    ContainerBaseVersion __CONTAINER_BASE_VERSION__

# help text displayed by 'singularity run-help __PIPELINE_NAME__-__PIPELINE_VERSION__.sif'
%help
    Source:    Michigan Data Interface
    Suite:     __SUITE_NAME__:__SUITE_VERSION__
    Pipeline:  __PIPELINE_NAME__:__PIPELINE_VERSION__
    Base:      __CONTAINER_BASE__:__CONTAINER_BASE_VERSION__
